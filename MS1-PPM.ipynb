{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf3c26e-070d-4da3-b766-6e4b586dc791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID  Satisfaction_Score  Feedback_Comments  Likelihood_to_Recommend\n",
      "0            1                10.0     Very satisfied                        9\n",
      "1            2                 3.0     Very satisfied                        3\n",
      "2            3                10.0     Very satisfied                        1\n",
      "3            4                 7.0  Needs improvement                        4\n",
      "4            5                 8.0     Unsatisfactory                        7\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5050 entries, 0 to 5049\n",
      "Data columns (total 4 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Customer_ID              5050 non-null   int64  \n",
      " 1   Satisfaction_Score       4949 non-null   float64\n",
      " 2   Feedback_Comments        5050 non-null   object \n",
      " 3   Likelihood_to_Recommend  5050 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 157.9+ KB\n",
      "None\n",
      "       Customer_ID  Satisfaction_Score  Likelihood_to_Recommend\n",
      "count  5050.000000         4949.000000              5050.000000\n",
      "mean    501.949703            5.684785                 5.571287\n",
      "std     288.806331            3.606511                 2.872577\n",
      "min       1.000000            1.000000                 1.000000\n",
      "25%     253.000000            3.000000                 3.000000\n",
      "50%     502.000000            6.000000                 6.000000\n",
      "75%     751.750000            8.000000                 8.000000\n",
      "max    1000.000000           60.000000                10.000000\n",
      "Customer_ID                  0\n",
      "Satisfaction_Score         101\n",
      "Feedback_Comments            0\n",
      "Likelihood_to_Recommend      0\n",
      "dtype: int64\n",
      "   Customer_ID  Satisfaction_Score  Feedback_Comments  \\\n",
      "0            1                10.0     very satisfied   \n",
      "1            2                 3.0     very satisfied   \n",
      "2            3                10.0     very satisfied   \n",
      "3            4                 7.0  needs improvement   \n",
      "4            5                 8.0     unsatisfactory   \n",
      "\n",
      "   Likelihood_to_Recommend Satisfaction_Level  \n",
      "0                        9               High  \n",
      "1                        3                Low  \n",
      "2                        1               High  \n",
      "3                        4             Medium  \n",
      "4                        7               High  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5050 entries, 0 to 5049\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   Customer_ID              5050 non-null   int64   \n",
      " 1   Satisfaction_Score       5050 non-null   float64 \n",
      " 2   Feedback_Comments        5050 non-null   object  \n",
      " 3   Likelihood_to_Recommend  5050 non-null   int64   \n",
      " 4   Satisfaction_Level       5050 non-null   category\n",
      "dtypes: category(1), float64(1), int64(2), object(1)\n",
      "memory usage: 163.0+ KB\n",
      "None\n",
      "       Customer_ID  Satisfaction_Score  Likelihood_to_Recommend\n",
      "count  5050.000000         5050.000000              5050.000000\n",
      "mean    501.949703            5.601386                 5.571287\n",
      "std     288.806331            2.807221                 2.872577\n",
      "min       1.000000            1.000000                 1.000000\n",
      "25%     253.000000            3.000000                 3.000000\n",
      "50%     502.000000            6.000000                 6.000000\n",
      "75%     751.750000            8.000000                 8.000000\n",
      "max    1000.000000           10.000000                10.000000\n",
      "Customer_ID                0\n",
      "Satisfaction_Score         0\n",
      "Feedback_Comments          0\n",
      "Likelihood_to_Recommend    0\n",
      "Satisfaction_Level         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "feedback = pd.read_csv('/Users/samleonor/Desktop/ITDA/DMP:MLPA/CFeedback.csv')\n",
    "\n",
    "# Inspect the dataset\n",
    "print(feedback.head())\n",
    "print(feedback.info())\n",
    "print(feedback.describe())\n",
    "print(feedback.isnull().sum()) \n",
    "\n",
    "# Fill missing values in Satisfaction_Score with the median\n",
    "feedback[\"Satisfaction_Score\"] = feedback[\"Satisfaction_Score\"].fillna(feedback[\"Satisfaction_Score\"].median())\n",
    "\n",
    "# Cap Satisfaction_Score at 10\n",
    "feedback[\"Satisfaction_Score\"] = feedback[\"Satisfaction_Score\"].clip(upper=10)\n",
    "\n",
    "# Clean Feedback_Comments\n",
    "feedback[\"Feedback_Comments\"] = (\n",
    "    feedback[\"Feedback_Comments\"]\n",
    "    .str.lower()  # Convert to lowercase\n",
    "    .str.strip()  # Remove leading/trailing spaces\n",
    "    .str.replace(r\"[^\\w\\s]\", \"\", regex=True)  # Remove special characters\n",
    ")\n",
    "\n",
    "# Categorize Satisfaction_Score into levels\n",
    "bins = [0, 4, 7, 10]\n",
    "labels = [\"Low\", \"Medium\", \"High\"]\n",
    "feedback[\"Satisfaction_Level\"] = pd.cut(\n",
    "    feedback[\"Satisfaction_Score\"], bins=bins, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Dataset check\n",
    "print(feedback.head())\n",
    "print(feedback.info())\n",
    "print(feedback.describe())\n",
    "print(feedback.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0d9c05-afe9-458e-a70b-03ed38a57eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product_ID                   Product_Name     Product_Type Risk_Level  \\\n",
      "0           1           Platinum Credit Card      Credit Card     Medium   \n",
      "1           2           Gold Savings Account  Savings Account        Low   \n",
      "2           3  High-Yield Investment Account       Investment       High   \n",
      "3           4                  Mortgage Loan             Loan     Medium   \n",
      "4           5                      Auto Loan             Loan     Medium   \n",
      "\n",
      "  Target_Income_Group  Risk_Level_numeric  \n",
      "0              Medium                   2  \n",
      "1                 Low                   1  \n",
      "2                High                   3  \n",
      "3                High                   2  \n",
      "4              Medium                   2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "proffering = pd.read_csv('/Users/samleonor/Desktop/ITDA/DMP:MLPA/PrOffering.csv')\n",
    "\n",
    "# Clean up column names\n",
    "proffering.columns = proffering.columns.str.strip()\n",
    "\n",
    "# Remove duplicates based on Product_ID\n",
    "proffering.drop_duplicates(subset=[\"Product_ID\"], inplace=True)\n",
    "\n",
    "# Drop the 'Target_Age_Group' column\n",
    "if 'Target_Age_Group' in proffering.columns:\n",
    "    proffering.drop(columns=['Target_Age_Group'], inplace=True)\n",
    "\n",
    "# Map Risk_Level to numeric values\n",
    "risk_map = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "proffering['Risk_Level_numeric'] = proffering['Risk_Level'].map(risk_map)\n",
    "\n",
    "print(proffering.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890b2418-b011-4bf3-b25e-2ff4f538460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction_ID  Customer_ID    Transaction_Date  Transaction_Amount  \\\n",
      "0               1          393 2023-01-01 00:00:00         3472.000000   \n",
      "1               2          826 2023-01-01 01:00:00         3094.726465   \n",
      "2               3          916 2023-01-01 02:00:00           10.000000   \n",
      "3               4          109 2023-01-01 03:00:00           72.000000   \n",
      "4               5          889 2023-01-01 04:00:00         1793.000000   \n",
      "\n",
      "  Transaction_Type  Product_ID  Transaction_Month Transaction_Weekday  \n",
      "0         Purchase         1.0                  1              Sunday  \n",
      "1     Bill Payment         2.0                  1              Sunday  \n",
      "2         Purchase         1.0                  1              Sunday  \n",
      "3       Investment         3.0                  1              Sunday  \n",
      "4       Investment         3.0                  1              Sunday  \n",
      "     Transaction_Date  Transaction_Month Transaction_Weekday\n",
      "0 2023-01-01 00:00:00                  1              Sunday\n",
      "1 2023-01-01 01:00:00                  1              Sunday\n",
      "2 2023-01-01 02:00:00                  1              Sunday\n",
      "3 2023-01-01 03:00:00                  1              Sunday\n",
      "4 2023-01-01 04:00:00                  1              Sunday\n",
      "Transaction_ID            0\n",
      "Customer_ID               0\n",
      "Transaction_Date          0\n",
      "Transaction_Amount        0\n",
      "Transaction_Type          0\n",
      "Product_ID             1294\n",
      "Transaction_Month         0\n",
      "Transaction_Weekday       0\n",
      "dtype: int64\n",
      "Transaction_ID                  int64\n",
      "Customer_ID                     int64\n",
      "Transaction_Date       datetime64[ns]\n",
      "Transaction_Amount            float64\n",
      "Transaction_Type               object\n",
      "Product_ID                    float64\n",
      "Transaction_Month               int32\n",
      "Transaction_Weekday            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "transactions = pd.read_csv('/Users/samleonor/Desktop/ITDA/DMP:MLPA/Transactions.csv')\n",
    "\n",
    "# Ensure Product_ID is correctly mapped based on Transaction_Type\n",
    "transaction_type_map = {\n",
    "    'Purchase': 1,\n",
    "    'Bill Payment': 2,\n",
    "    'Investment': 3\n",
    "}\n",
    "transactions['Product_ID'] = transactions['Transaction_Type'].map(transaction_type_map)\n",
    "\n",
    "# Fill missing values in Transaction_Amount with 0\n",
    "transactions['Transaction_Amount'] = transactions['Transaction_Amount'].fillna(0)\n",
    "\n",
    "# Replace 0 values in Transaction_Amount with the mean (excluding zeros)\n",
    "mean_value = transactions[transactions['Transaction_Amount'] != 0]['Transaction_Amount'].mean()\n",
    "transactions['Transaction_Amount'] = transactions['Transaction_Amount'].replace(0.0, mean_value)\n",
    "\n",
    "# Convert Transaction_Date to datetime format\n",
    "transactions['Transaction_Date'] = pd.to_datetime(transactions['Transaction_Date'])\n",
    "\n",
    "# Extract month and weekday from Transaction_Date\n",
    "transactions['Transaction_Month'] = transactions['Transaction_Date'].dt.month\n",
    "transactions['Transaction_Weekday'] = transactions['Transaction_Date'].dt.day_name()\n",
    "\n",
    "# Dataset check\n",
    "print(transactions.head())\n",
    "print(transactions[['Transaction_Date', 'Transaction_Month', 'Transaction_Weekday']].head())\n",
    "print(transactions.isnull().sum())\n",
    "print(transactions.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e848d05-ffb5-4fe6-a2eb-937c3019d4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " Purchased\n",
      "0    12831\n",
      "1     6314\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.5411334552102377\n",
      "Precision: 0.3603504928806134\n",
      "Recall: 0.5276663993584603\n",
      "F1-Score: 0.428246013667426\n",
      "ROC-AUC: 0.5330969384617582\n",
      "Model Coefficients: [[-0.00074671  0.00341052 -0.02935525  0.09008418 -0.01796472 -0.06384409\n",
      "  -0.00674278 -0.06503396  0.01369161 -0.06550374 -0.09473139]]\n",
      "Model Intercept: [-0.00313538]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class Distribution:\\n\", merged_data['Purchased'].value_counts())\n",
    "\n",
    "# Feature Engineering\n",
    "features = [\n",
    "    'Satisfaction_Score', 'Likelihood_to_Recommend', 'Transaction_Amount',\n",
    "    'Transaction_Month', 'Risk_Level_numeric'\n",
    "]\n",
    "\n",
    "# Add one-hot encoded weekday columns\n",
    "weekday_columns = [col for col in merged_data.columns if 'Transaction_Weekday_' in col]\n",
    "features.extend(weekday_columns)\n",
    "\n",
    "# Define X (features) and y (target variable)\n",
    "x = merged_data[features]\n",
    "y = merged_data['Purchased']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the Logistic Regression Model\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "\n",
    "# Interpret results\n",
    "print(\"Model Coefficients:\", model.coef_)\n",
    "print(\"Model Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a912996-e9ef-4e2c-a06d-188e156b0c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
